{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6163f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torchvision\n",
    "from skimage import io\n",
    "import cv2\n",
    "\n",
    "import copy, json\n",
    "import numpy as np\n",
    "from pytorch_memlab import LineProfiler\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c9b1d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "options = ['0', '1', '2', '3', '4', '5', 'yes', 'no', 'rubber', 'metal', 'sphere', 'cube', 'cylinder', 'gray', 'brown', 'green', 'red', 'blue', 'purple', 'yellow', 'cyan']\n",
    "option_id_map = {\n",
    "    o:i for i,o in enumerate(options)\n",
    "}\n",
    "id_option_map = {\n",
    "    i:o for i,o in enumerate(options)\n",
    "}\n",
    "task_heads = ['descriptive', 'explanatory', 'predictive', 'counterfactual']\n",
    "binary_id_map = {'wrong': 0, 'correct': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306cbca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessQuestions:\n",
    "    def __init__(self, task_head):\n",
    "        self.task_head = task_head\n",
    "        \n",
    "    def get_qa_batch(self, ques_list):\n",
    "        #TODO: get qa batches for the current task_head\n",
    "        \n",
    "        if self.task_head == \"descriptive\":\n",
    "            return self._get_descriptive_qa(ques_list)\n",
    "        elif self.task_head == \"explanatory\":\n",
    "            return self._get_explanatory_qa(ques_list)\n",
    "        elif self.task_head == \"predictive\":\n",
    "            return self._get_predictive_qa(ques_list)\n",
    "        elif self.task_head == \"counterfactual\":\n",
    "            return self._get_counterfactual_qa(ques_list)\n",
    "        else:\n",
    "            pass       \n",
    "        \n",
    "        return # Tokenized Question answer Pairs\n",
    "    \n",
    "    def _get_descriptive_qa(self, ques_list):\n",
    "        '''\n",
    "        ques_list: list of question_data dictionary\n",
    "        question_list: list of <question> [SEP] <question_subtype>\n",
    "        answer_list: list of respective answer as option_id_map\n",
    "        '''\n",
    "        question_list = list()\n",
    "        answer_list = list()\n",
    "        \n",
    "        for j, q in enumerate(ques_list):\n",
    "            \n",
    "            if q['question_type'] == self.task_head:                \n",
    "                question = q['question']\n",
    "                question_subtype = q['question_subtype']\n",
    "                answer = q['answer']\n",
    "                \n",
    "                question_list.append(question + \" [SEP] \" + question_subtype)\n",
    "                answer_list.append(option_id_map[answer])\n",
    "        \n",
    "        return tokenizer(question_list, return_tensors='pt', padding=True), torch.tensor(answer_list)\n",
    "    \n",
    "    def _get_explanatory_qa(self, ques_list):\n",
    "        '''\n",
    "        ques_list: list of question_data dictionary\n",
    "        question_list: list of <question> [SEP] <choice_k>\n",
    "        answer_list: list of respective answer as binary_id_map correct = 1 / wrong = 0\n",
    "        '''\n",
    "        question_list = list()\n",
    "        answer_list = list()\n",
    "        \n",
    "        for j, q in enumerate(ques_list):\n",
    "            \n",
    "            if q['question_type'] == self.task_head:                \n",
    "                question = q['question']\n",
    "                \n",
    "                for c, choice in enumerate(q['choices']):\n",
    "                    question_list.append(question + \" [SEP] \" + choice['choice'])\n",
    "                    answer_list.append(binary_id_map[choice['answer']])\n",
    "            \n",
    "        if len(question_list) > 0:\n",
    "            return tokenizer(question_list, return_tensors='pt', padding=True), torch.tensor(answer_list).float()\n",
    "        else:\n",
    "            return torch.LongTensor([]), torch.LongTensor([]) # HANDLE THIS IN TRAINING\n",
    "        \n",
    "    def _get_predictive_qa(self, ques_list):\n",
    "        '''\n",
    "        ques_list: list of question_data dictionary\n",
    "        question_list: list of <question> [SEP] <choice_k>\n",
    "        answer_list: list of respective answer as binary_id_map correct = 1 / wrong = 0\n",
    "        '''\n",
    "        question_list = list()\n",
    "        answer_list = list()\n",
    "        \n",
    "        for j, q in enumerate(ques_list):\n",
    "            \n",
    "            if q['question_type'] == self.task_head:                \n",
    "                question = q['question']\n",
    "                \n",
    "                for c, choice in enumerate(q['choices']):\n",
    "                    question_list.append(question + \" [SEP] \" + choice['choice'])\n",
    "                    answer_list.append(binary_id_map[choice['answer']])\n",
    "                    \n",
    "#         print(len(question_list), question_list, len(answer_list), answer_list)\n",
    "        if len(question_list) > 0:\n",
    "            return tokenizer(question_list, return_tensors='pt', padding=True), torch.tensor(answer_list)\n",
    "        else:\n",
    "            return torch.LongTensor([]), torch.LongTensor([]) # HANDLE THIS IN TRAINING\n",
    "    \n",
    "    def _get_counterfactual_qa(self, ques_list):\n",
    "        '''\n",
    "        ques_list: list of question_data dictionary\n",
    "        question_list: list of <question> [SEP] <choice_k>\n",
    "        answer_list: list of respective answer as binary_id_map correct = 1 / wrong = 0\n",
    "        '''\n",
    "        question_list = list()\n",
    "        answer_list = list()\n",
    "        \n",
    "        for j, q in enumerate(ques_list):\n",
    "            \n",
    "            if q['question_type'] == self.task_head:                \n",
    "                question = q['question']\n",
    "                \n",
    "                for c, choice in enumerate(q['choices']):\n",
    "                    question_list.append(question + \" [SEP] \" + choice['choice'])\n",
    "                    answer_list.append(binary_id_map[choice['answer']])\n",
    "            \n",
    "        if len(question_list) > 0:\n",
    "            return tokenizer(question_list, return_tensors='pt', padding=True), torch.tensor(answer_list).float()\n",
    "        else:\n",
    "            return torch.LongTensor([]), torch.LongTensor([]) # HANDLE THIS IN TRAINING\n",
    "        \n",
    "class CLEVRERDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_dir, frame_dir, task_head='descriptive', img_transform=None):\n",
    "        # TODO load annotations\n",
    "        assert os.path.isdir(data_dir)\n",
    "        assert os.path.isdir(frame_dir)\n",
    "        \n",
    "        with open(os.path.join(data_dir, data_dir.split(\"/\")[-1] + \".json\"), \"r\") as f:\n",
    "            self.json_data = json.load(f)\n",
    "        self.frame_dir = frame_dir\n",
    "        self.task_head = task_head\n",
    "        \n",
    "        # self.img_transform = img_transform\n",
    "        self.process_questions = ProcessQuestions(task_head)\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        # get length from directory\n",
    "        return len(self.json_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        TODO: \n",
    "        1. Change here hardcoded path in frame_paths to os.path.join(self.frame_dir, f\"sim_{vid_id}\", \"*.png\")\n",
    "        2. Check normalization mean and std values used in image transform\n",
    "        3. Add tokenized questions + concatinate options (where applicable) and answer token\n",
    "        4. There are certain videos for which there are no predictive questions. Handle it during training loop\n",
    "            coz dataloader will return torch.LongTensor([]), torch.LongTensor([]). This may happen for explanatory and counterfactual questions as well.\n",
    "        \"\"\"\n",
    "        \n",
    "        vid_json = self.json_data[idx]\n",
    "        vid_id = vid_json['scene_index']\n",
    "        frame_dir = os.path.join(self.frame_dir, f\"sim_{vid_id:05d}\", \"*.png\")\n",
    "        frame_paths = glob(frame_dir)\n",
    "        frames = torch.stack([torchvision.io.read_image(img).float() for img in frame_paths])\n",
    "                \n",
    "        ques_toks, answers = self.process_questions.get_qa_batch(vid_json['questions'])\n",
    "#         answers = torch.LongTensor(answers)\n",
    "        return {'frames': frames, 'ques_toks': ques_toks, 'answers': answers}\n",
    "    \n",
    "def get_task_head(epoch):\n",
    "    task_head = ''\n",
    "    for t in range(4):\n",
    "        if (epoch+1) % (t+1) == 0:\n",
    "            task_head = task_heads[t]\n",
    "    return task_head\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cca1fec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_y, dim_x, max_len=300, p=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        self.pe = torch.zeros(max_len, dim_y, dim_x)\n",
    "\n",
    "        pos = torch.arange(0,max_len).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        div_term_x = torch.exp(torch.arange(0, dim_x, 2).expand((dim_y//2,dim_x//2)) * -(np.log(10000.0) / dim_x))\n",
    "        div_term_y = torch.exp(torch.arange(0, dim_y, 2).unsqueeze(1).expand((dim_y//2,dim_x//2)) * -(np.log(10000.0) / dim_y))\n",
    "\n",
    "        self.pe[:, 0::2, 0::2] = (torch.sin(pos * div_term_x) + torch.sin(pos * div_term_y))/2\n",
    "        self.pe[:, 1::2, 1::2] = (torch.cos(pos * div_term_x) + torch.cos(pos * div_term_y))/2\n",
    "        self.pe = self.pe.unsqueeze(0).repeat(3,1,1,1).transpose(0,1).reshape((3*max_len,dim_y,dim_x))\n",
    "        self.pe = self.pe * 0.05\n",
    "        # assert((self.pe[0] == self.pe[1]) & (self.pe[1] == self.pe[2])).all()\n",
    "        # self.pe = self.pe.unsqueeze(0)\n",
    "        # self.register_buffer(\"pe\", self.pe)\n",
    "\n",
    "        # self.dropout = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x+self.pe[:x.shape[0],:,:].requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccf9d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertCNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size=768):\n",
    "        super().__init__()\n",
    "        self.cnn = torchvision.models.resnet50(pretrained=True)\n",
    "        self.cnn.fc = nn.Identity()\n",
    "        \n",
    "        for name, param in self.cnn.named_parameters():\n",
    "            if not name.startswith('layer4'):\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "                input_size=2048,\n",
    "                batch_first=True,\n",
    "                hidden_size=hidden_size,\n",
    "                num_layers=1\n",
    "            )\n",
    "        self.bert = transformers.BertModel.from_pretrained('bert-base-cased')\n",
    "        \n",
    "        # self.pos_emb = PositionalEmbedding(320, 480)\n",
    "        \n",
    "        self.h0 = nn.Parameter(torch.empty(1,hidden_size).normal_(0, 0.1))\n",
    "        self.c0 = nn.Parameter(torch.empty(1,hidden_size).normal_(0, 0.1))\n",
    "        \n",
    "    def forward(self, frames, tokens):\n",
    "        \n",
    "        # frames = (n_frames, channels, h, w)\n",
    "        N, C, H, W = frames.shape\n",
    "        i = 0\n",
    "        bs = 8\n",
    "        frame_emb = []\n",
    "        while (i*bs < N):\n",
    "            frame_emb += [self.cnn(frames[i*bs:(i+1)*bs])]\n",
    "            i += 1\n",
    "            \n",
    "        frame_emb = torch.vstack(frame_emb)\n",
    "        frame_encs, (video_enc, last_cell_state) = self.lstm(frame_emb, (self.h0, self.c0))\n",
    "        \n",
    "        bert_output = self.bert(**tokens)\n",
    "        \n",
    "        # feature vector - 1768-dimensional\n",
    "        features = torch.hstack([video_enc.repeat(bert_output.pooler_output.size(0),1), bert_output.pooler_output])\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75fd5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DescriptiveTaskHead(nn.Module):\n",
    "\t\n",
    "\tdef __init__(self, n_classes=21, p=0.2, input_dim=768*2):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.clf = nn.Sequential(\n",
    "\t\t\tnn.Linear(input_dim, 1024),\n",
    "\t\t\tnn.Dropout(p=0.2),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(p=0.2),\n",
    "\t\t\tnn.Linear(1024, n_classes)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, features):\n",
    "\t\treturn self.clf(features)\n",
    "\n",
    "class ExplanatoryTaskHead(nn.Module):\n",
    "\t\n",
    "\tdef __init__(self, p=0.2, input_dim=768*2):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.clf = nn.Sequential(\n",
    "\t\t\tnn.Linear(input_dim, 1024),\n",
    "\t\t\tnn.Dropout(p=0.2),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(p=0.2),\n",
    "\t\t\tnn.Linear(1024, 1),\n",
    "            nn.Sigmoid()\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, features):\n",
    "\t\treturn self.clf(features).squeeze()\n",
    "\n",
    "class PredictiveTaskHead(nn.Module):\n",
    "\t\n",
    "\tdef __init__(self, n_classes=2, p=0.2, input_dim=768*2):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.clf = nn.Sequential(\n",
    "\t\t\tnn.Linear(input_dim, 1024),\n",
    "\t\t\tnn.Dropout(p=0.2),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(p=0.2),\n",
    "\t\t\tnn.Linear(1024, n_classes)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, features):\n",
    "\t\treturn self.clf(features)\n",
    "\n",
    "class CounterfactualTaskHead(nn.Module):\n",
    "\t\n",
    "\tdef __init__(self, p=0.2, input_dim=768*2):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.clf = nn.Sequential(\n",
    "\t\t\tnn.Linear(input_dim, 1024),\n",
    "\t\t\tnn.Dropout(p=0.2),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(p=0.2),\n",
    "\t\t\tnn.Linear(1024, 1),\n",
    "            nn.Sigmoid()\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, features):\n",
    "\t\treturn self.clf(features).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "683d582a-28ef-464f-9b87-fabb20cdaee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_collate_fn(data):\n",
    "    return data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a67fbb-eb5f-46ee-8f5a-1d97e7f48051",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ead6b217-ad1d-4abe-a3d6-21540902be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "612cedd2-2783-4465-becd-3b2308e7b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = torchvision.transforms.Compose([torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                                                     (0.2023, 0.1994, 0.2010))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f8ae8de-07bb-4d1f-83d3-dd3c2c732a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CLEVRERDataset(data_dir=\"../../data/data/train\", frame_dir=\"../../clevrer_code/frames\")\n",
    "val_ds = CLEVRERDataset(data_dir=\"../../data/data/validation\", frame_dir=\"../../clevrer_code/frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55196731-fb9a-4c31-8835-501a9b31cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "if DEBUG:\n",
    "    train_ds.json_data = train_ds.json_data[:16]\n",
    "    val_ds.json_data = val_ds.json_data[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3441ec07-b779-4294-926d-e9d70f51ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=1, collate_fn=dl_collate_fn, shuffle=True, num_workers=4)\n",
    "val_dl = DataLoader(val_ds, batch_size=1, collate_fn=dl_collate_fn, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00514a13-043d-4c77-9ff7-99f97cd3e741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertCNNModel().to(device)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43f47698-8929-410e-9f4b-fc3b1906e8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = {\n",
    "    'descriptive': DescriptiveTaskHead(),\n",
    "    'predictive': PredictiveTaskHead(),\n",
    "    'explanatory': ExplanatoryTaskHead(),\n",
    "    'counterfactual': CounterfactualTaskHead()\n",
    "}\n",
    "\n",
    "heads = {a:b.to(device) for a,b in heads.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f83a4bb5-d61e-4ce2-bc67-8324d665c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam([{'params': model.parameters(), 'lr': 1e-5}] + [{'params': head.parameters(), 'lr': 1e-4} for head in heads.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "384a3f16-0a95-45b9-b9f2-561f39c042ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, heads, train_dl, val_dl, optimizer, scheduler=None, max_epochs=4, patience_lim=2):\n",
    "\n",
    "    best_model = None\n",
    "    best_val_loss = 10000\n",
    "    val_losses = {t:[] for t in task_heads}\n",
    "    train_losses = {t:[] for t in task_heads}\n",
    "    val_question_count = {t:0 for t in task_heads}\n",
    "    \n",
    "    patience = 0\n",
    "    \n",
    "    loss_fns = {\n",
    "        'descriptive': nn.CrossEntropyLoss(reduction='sum'),\n",
    "        'predictive': nn.CrossEntropyLoss(reduction='sum'),\n",
    "        'explanatory': nn.BCELoss(reduction='sum'),\n",
    "        'counterfactual': nn.BCELoss(reduction='sum')\n",
    "    }\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "\n",
    "        print(f\"\\n\\n|----------- EPOCH: {epoch} -----------|\")\n",
    "        for task in task_heads:\n",
    "            train_dl.dataset.task_head = task\n",
    "            train_dl.dataset.process_questions = ProcessQuestions(task)\n",
    "            val_dl.dataset.task_head = task\n",
    "            val_dl.dataset.process_questions = ProcessQuestions(task)\n",
    "            print(f\"  Training for {task} task head.\")\n",
    "            n_train_questions = 0\n",
    "            n_val_questions = 0\n",
    "            \n",
    "            train_loss = 0\n",
    "            model.train()\n",
    "            for batch in tqdm(train_dl):\n",
    "                if len(batch['answers']) == 0:\n",
    "                    continue\n",
    "                frames = img_transform(batch['frames'].to(device)) #torch.Size([128, 3, 320, 480])\n",
    "                ques_toks = batch['ques_toks'].to(device) # returns [N, k_question || choice, toks_len] for bert we may need to squeeze ques_toks['input_ids'],ques_toks['token_type_ids'], ques_toks['attention_mask'] \n",
    "                answers = batch['answers'].to(device)\n",
    "                # print(\"\\nSHAPES frames: {}, ques_toks['input_ids']: {}, ques_toks['token_type_ids']: {}, ques_toks['attention_mask']: {}, answers: {}\".format(frames.shape, ques_toks['input_ids'].shape, ques_toks['token_type_ids'].shape, \n",
    "                #       ques_toks['attention_mask'].shape, answers))\n",
    "                n_questions = ques_toks['input_ids'].size(1)\n",
    "                n_train_questions += n_questions\n",
    "            \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(frames, ques_toks)\n",
    "                outputs = heads[task](outputs)\n",
    "                \n",
    "                loss = loss_fns[task](outputs, answers)\n",
    "                mean_loss = loss / n_questions\n",
    "                mean_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.detach()\n",
    "                \n",
    "            train_loss = train_loss.cpu() / n_train_questions\n",
    "            print(f'  {task} Train Loss: {train_loss}')\n",
    "            train_losses[task].append(train_loss)\n",
    "\n",
    "            val_loss = 0\n",
    "            model.eval()\n",
    "            for batch in tqdm(val_dl):\n",
    "                if len(batch['answers']) == 0:\n",
    "                    continue\n",
    "                frames = img_transform(batch['frames'].to(device)) #torch.Size([128, 3, 320, 480])\n",
    "                ques_toks = batch['ques_toks'].to(device) # returns [N, k_question || choice, toks_len] for bert we may need to squeeze ques_toks['input_ids'],ques_toks['token_type_ids'], ques_toks['attention_mask'] \n",
    "                \n",
    "                answers = batch['answers'].to(device)\n",
    "                n_questions = ques_toks['input_ids'].size(1)\n",
    "                n_val_questions += n_questions\n",
    "            \n",
    "                outputs = model(frames, ques_toks)\n",
    "                outputs = heads[task](outputs)\n",
    "                loss = loss_fns[task](outputs, answers)\n",
    "\n",
    "                val_loss += loss.detach()\n",
    "            \n",
    "            val_question_count[task] = n_val_questions\n",
    "                \n",
    "            val_loss = val_loss.cpu() / n_val_questions\n",
    "            print(f'  {task} Val Loss: {val_loss}')\n",
    "            val_losses[task].append(val_loss)\n",
    "            print('')\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        # early stopping\n",
    "        agg_val_loss = sum([val_losses[t][-1]*val_question_count[t] for t in task_heads])/sum(val_question_count.values())\n",
    "        if agg_val_loss >= best_val_loss:\n",
    "            if patience >= patience_lim:\n",
    "                break\n",
    "            else:\n",
    "                patience += 1\n",
    "        else:\n",
    "            patience = 0\n",
    "            best_val_loss = agg_val_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_model = best_model.cpu()\n",
    "    \n",
    "    return best_model, (train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "169eaeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|----------- EPOCH: 0 -----------|\n",
      "  Training for descriptive task head.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f4ae72ccf064b0f854b117cdaf5acfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  descriptive Train Loss: 1.3230302333831787\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e990847847442dbcc68851ce84966e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  descriptive Val Loss: 1.1488888263702393\n",
      "\n",
      "  Training for explanatory task head.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf60deecdf044bfa9c388fa3492e1f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  explanatory Train Loss: 0.14633840322494507\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93c10823ad441e283e90ec03ef686e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  explanatory Val Loss: 0.1368873417377472\n",
      "\n",
      "  Training for predictive task head.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e03d3569b2e432db001803604f9a8fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  predictive Train Loss: 0.08479803800582886\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5692ebbf2a8448caac6615fefdb93ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  predictive Val Loss: 0.07608041912317276\n",
      "\n",
      "  Training for counterfactual task head.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6749f271c440fc90fd8acab53b965c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "    self._shutdown_workers()Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "Exception ignored in:   File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "\n",
      "      File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "    if w.is_alive():\n",
      "Traceback (most recent call last):\n",
      "if w.is_alive():  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "          File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "    AssertionError\n",
      "self._shutdown_workers()  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    \n",
      ":     if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "\n",
      "\n",
      "AssertionError    : \n",
      "if w.is_alive():  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "can only test a child process\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "\n",
      "    Exception ignored in: Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'    assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>\n",
      "AssertionError\n",
      "\n",
      ": Traceback (most recent call last):\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "can only test a child processAssertionError    <function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>\n",
      ": self._shutdown_workers()\n",
      "\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "    Traceback (most recent call last):\n",
      "can only test a child process\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "self._shutdown_workers()Exception ignored in:         \n",
      "self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>if w.is_alive():\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "\n",
      "      File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "if w.is_alive():\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "Traceback (most recent call last):\n",
      "\n",
      "      File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "if w.is_alive():    \n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "self._shutdown_workers()AssertionError:     can only test a child process    assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "\n",
      "    AssertionErrorif w.is_alive():: can only test a child processAssertionError\n",
      "\n",
      ":   File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: can only test a child process\n",
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20><function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20><function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "\n",
      "    \n",
      "\n",
      "Traceback (most recent call last):\n",
      "self._shutdown_workers()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "    self._shutdown_workers()          File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "\n",
      "if w.is_alive():self._shutdown_workers()  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "\n",
      "      File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    \n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "self._shutdown_workers()        if w.is_alive():\n",
      "\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "if w.is_alive():  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "if w.is_alive():    AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "    : \n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "    \n",
      "AssertionErrorAssertionErrorException ignored in: : <function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process\n",
      ": \n",
      "\n",
      "AssertionError: Traceback (most recent call last):\n",
      "can only test a child processException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>can only test a child process\n",
      "Exception ignored in:   File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "\n",
      "\n",
      "    Traceback (most recent call last):\n",
      "self._shutdown_workers()  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>\n",
      "Exception ignored in:   File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "    \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>    self._shutdown_workers()\n",
      "if w.is_alive():Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "\n",
      "    Traceback (most recent call last):\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "      File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "    if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "self._shutdown_workers()\n",
      ":     assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "    self._shutdown_workers()can only test a child process\n",
      "    \n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "if w.is_alive():    Exception ignored in: Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>if w.is_alive():\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError:   File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "      File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "self._shutdown_workers()\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "      File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "    self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "\n",
      "AssertionErrorException ignored in: self._shutdown_workers()\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "    if w.is_alive():: \n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'    if w.is_alive():\n",
      "Traceback (most recent call last):\n",
      "can only test a child process  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "\n",
      "\n",
      "\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    AssertionErrorException ignored in:     : assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>\n",
      "can only test a child process\n",
      "self._shutdown_workers()Traceback (most recent call last):\n",
      "\n",
      "\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "Exception ignored in: AssertionError<function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>: \n",
      "Traceback (most recent call last):\n",
      "      File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "self._shutdown_workers()    \n",
      "      File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "can only test a child process\n",
      "if w.is_alive():self._shutdown_workers()Exception ignored in: \n",
      "    \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "if w.is_alive():Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "      File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "      File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    AssertionErrorself._shutdown_workers(): can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "    \n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError    : \n",
      "if w.is_alive():can only test a child processAssertionError\n",
      "\n",
      ":   File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "can only test a child processException ignored in:     \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "Traceback (most recent call last):\n",
      "AssertionError  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      ":     can only test a child processself._shutdown_workers()\n",
      "\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  counterfactual Train Loss: 0.18894509971141815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17885b230a9c4f528c8a2bf8dd26594d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  counterfactual Val Loss: 0.18938200175762177\n",
      "\n",
      "\n",
      "\n",
      "|----------- EPOCH: 1 -----------|\n",
      "  Training for descriptive task head.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af30ebe94e5943fca7ff139da67ef3b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  descriptive Train Loss: 1.1126339435577393\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c118a94d7b14a069b288ad3021ce776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  descriptive Val Loss: 1.054560899734497\n",
      "\n",
      "  Training for explanatory task head.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abec4d71bcff47fea0cacf0404653fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  explanatory Train Loss: 0.1893351972103119\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c801bd1ada5a4ced87bc4c07bf3e3b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  explanatory Val Loss: 0.16842657327651978\n",
      "\n",
      "  Training for predictive task head.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb86e82f6714cdfa8d1622a93058408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "    self._shutdown_workers()Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>Exception ignored in: Traceback (most recent call last):\n",
      "\n",
      "\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>Traceback (most recent call last):\n",
      "    \n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "    self._shutdown_workers()Traceback (most recent call last):\n",
      "if w.is_alive():\n",
      "      File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "self._shutdown_workers()\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "    if w.is_alive():  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "\n",
      "\n",
      "      File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "    if w.is_alive():  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "AssertionError: AssertionError    can only test a child process  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      ": \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>\n",
      "can only test a child processcan only test a child process\n",
      "\n",
      "AssertionErrorTraceback (most recent call last):\n",
      ": \n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "Exception ignored in: can only test a child process    <function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>Exception ignored in: self._shutdown_workers()\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>Traceback (most recent call last):\n",
      "\n",
      "\n",
      "Exception ignored in:   File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "    <function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "    \n",
      "self._shutdown_workers()if w.is_alive():Traceback (most recent call last):\n",
      "    \n",
      "self._shutdown_workers()  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    \n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError    self._shutdown_workers(): can only test a child process\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "        if w.is_alive():if w.is_alive():\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "\n",
      "\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n",
      "    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      ": can only test a child process\n",
      "Exception ignored in: \n",
      "Exception ignored in:     assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20><function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>AssertionError\n",
      "\n",
      "\n",
      ": Traceback (most recent call last):\n",
      "can only test a child processTraceback (most recent call last):\n",
      "AssertionError\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      ": can only test a child process      File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>\n",
      "    \n",
      "self._shutdown_workers()Traceback (most recent call last):\n",
      "Exception ignored in: self._shutdown_workers()  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "    \n",
      "    self._shutdown_workers()Traceback (most recent call last):\n",
      "if w.is_alive():\n",
      "      File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "      File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "if w.is_alive():\n",
      "if w.is_alive():      File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "\n",
      "\n",
      "self._shutdown_workers()  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    \n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "        \n",
      "    if w.is_alive():AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process': \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "\n",
      "AssertionError: can only test a child process\n",
      "can only test a child processException ignored in: \n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>\n",
      "AssertionError    : Traceback (most recent call last):\n",
      "can only test a child process\n",
      "Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>Traceback (most recent call last):\n",
      "AssertionError  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      ": \n",
      "    Traceback (most recent call last):\n",
      "can only test a child process    self._shutdown_workers()  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "self._shutdown_workers()\n",
      "    \n",
      "\n",
      "self._shutdown_workers()  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>\n",
      "        \n",
      "if w.is_alive():if w.is_alive():\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "      File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'self._shutdown_workers()    \n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
      "AssertionError    if w.is_alive():: : can only test a child processcan only test a child process\n",
      "\n",
      "\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  predictive Train Loss: 0.0830671638250351\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abddeeb6a97e46ba91424e35e0202be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  predictive Val Loss: 0.08486644923686981\n",
      "\n",
      "  Training for counterfactual task head.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6274ada16f574f18a978c2aeed7ba17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  counterfactual Train Loss: 0.20385690033435822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b457a5407362456e9f9f86a9840c6a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  counterfactual Val Loss: 0.19508667290210724\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2ad5844eac20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1445, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/popen_fork.py\", line 45, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/cse/btech/cs1200869/.conda/envs/dl_35/lib/python3.7/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|----------- EPOCH: 2 -----------|\n",
      "  Training for descriptive task head.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f740fdd9490145cb8d11858a333ec6ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  descriptive Train Loss: 1.0272712707519531\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fccb99c624cc42f193911706a8cf1ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  descriptive Val Loss: 1.0174094438552856\n",
      "\n",
      "  Training for explanatory task head.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1336e525b04bc6b880e1bd0fe50d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  explanatory Train Loss: 0.1366216391324997\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097837d8b04446d8b5144c834aa98ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  explanatory Val Loss: 0.13653792440891266\n",
      "\n",
      "  Training for predictive task head.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c78a7446ada48159322be5a7d7bb52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  predictive Train Loss: 0.07630564272403717\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949c2aac64e24130b4a63dfd86a002dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  predictive Val Loss: 0.07842875272035599\n",
      "\n",
      "  Training for counterfactual task head.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a2fb73dc6f434fb53618a93496ee2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  counterfactual Train Loss: 0.1954161375761032\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b7afa521df24856be3823b23172284e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  counterfactual Val Loss: 0.19782914221286774\n",
      "\n",
      "\n",
      "\n",
      "|----------- EPOCH: 3 -----------|\n",
      "  Training for descriptive task head.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9659489fe3406b8b7390e18cca006d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  descriptive Train Loss: 0.9899421334266663\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea47646ceb54d2494b5572430b966e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  descriptive Val Loss: 0.9558086395263672\n",
      "\n",
      "  Training for explanatory task head.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ede231a0e74e50adda8855c682c9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  explanatory Train Loss: 0.14060406386852264\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2806ed33509347a0ab66765670ec9641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  explanatory Val Loss: 0.13796192407608032\n",
      "\n",
      "  Training for predictive task head.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905c62b2b94243b880b75366511b1a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  predictive Train Loss: 0.08437743037939072\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b49cc4fd54451b8e7269f53ef64616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  predictive Val Loss: 0.07913472503423691\n",
      "\n",
      "  Training for counterfactual task head.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e3e96e72c94b9eae6efb7560a3ca40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  counterfactual Train Loss: 0.1954578459262848\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2930a7d18a41d38ea87102502a1324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  counterfactual Val Loss: 0.18706245720386505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, (train_losses, val_losses) = train(model, heads, train_dl, val_dl, optimizer)\n",
    "torch.save(best_model, '../models/bert_cnn_baseline.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6697fd8b-6bd6-44d5-88c1-7d8e627cd465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
