{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6e4d828-6b9a-4631-a6c1-9f18d620d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import copy, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ca62db2c-73c4-40c1-accc-58dfc59b1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e46eee0-b033-4893-a936-ea4aaedb3fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLEVRERDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_dir, frame_dir):\n",
    "        # TODO load annotations\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        # get length from directory\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1b106a6d-1da8-4816-b35e-bba71a0bc2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_y, dim_x, max_len=300, p=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        self.pe = torch.zeros(max_len, dim_y, dim_x)\n",
    "\n",
    "        pos = torch.arange(0,max_len).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        div_term_x = torch.exp(torch.arange(0, dim_x, 2).expand((dim_y//2,dim_x//2)) * -(np.log(10000.0) / dim_x))\n",
    "        div_term_y = torch.exp(torch.arange(0, dim_y, 2).unsqueeze(1).expand((dim_y//2,dim_x//2)) * -(np.log(10000.0) / dim_y))\n",
    "\n",
    "        self.pe[:, 0::2, 0::2] = (torch.sin(pos * div_term_x) + torch.sin(pos * div_term_y))/2\n",
    "        self.pe[:, 1::2, 1::2] = (torch.cos(pos * div_term_x) + torch.cos(pos * div_term_y))/2\n",
    "        self.pe = self.pe.unsqueeze(0).repeat(3,1,1,1).transpose(0,1).reshape((3*max_len,dim_y,dim_x))\n",
    "        # assert((self.pe[0] == self.pe[1]) & (self.pe[1] == self.pe[2])).all()\n",
    "        # self.pe = self.pe.unsqueeze(0)\n",
    "        # self.register_buffer(\"pe\", self.pe)\n",
    "\n",
    "        # self.dropout = nn.Dropout(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        print(self.pe.shape)\n",
    "        return x+self.pe[:x.shape[1],:,:].requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "78c47e5f-6d1d-4cb1-89f5-a0f84ae4750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertCNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = torchvision.models.resnet50(pretrained=True)\n",
    "        self.bert = transformers.BertModel.from_pretrained('bert-base-cased')\n",
    "        \n",
    "        self.pos_emb = PositionalEmbedding(320, 480)\n",
    "        \n",
    "    def forward(self, frames, tokens):\n",
    "        \n",
    "        bert_output = self.bert(**tokens)\n",
    "        cnn_output = self.cnn(self.pos_emb(frames))\n",
    "        \n",
    "        # feature vector - 1768-dimensional\n",
    "        features = torch.hstack([cnn_output, bert_output.pooler_output])\n",
    "        \n",
    "        return features\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fbfa2f84-2148-4599-9a0b-b4eb1f521256",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DescriptiveTaskHead(nn.Module):\n",
    "\t\n",
    "\tdef __init__(self, n_classes=21, p=0.2):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.clf = nn.Sequential(\n",
    "\t\t\tnn.Linear(1768, 1024),\n",
    "\t\t\tnn.Dropout(p=0.2),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(p=0.2),\n",
    "\t\t\tnn.Linear(1024, 1024),\n",
    "\t\t\tnn.Dropout(p=0.2),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(1024, n_classes)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, features):\n",
    "\t\t# features: (b,1768)\n",
    "\t\treturn self.clf(features)\n",
    "\n",
    "class ExplanatoryTaskHead(nn.Module):\n",
    "\t\n",
    "\tdef __init__(self, p=0.2):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.clf = nn.Sequential(\n",
    "\t\t\tnn.Linear(1768, 1024),\n",
    "\t\t\tnn.Dropout(p=0.2),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(p=0.2),\n",
    "\t\t\tnn.Linear(1024, 1024),\n",
    "\t\t\tnn.Dropout(p=0.2),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(1024, 1),\n",
    "            nn.Sigmoid()\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, features):\n",
    "\t\t# features: (b,1768)\n",
    "\t\treturn self.clf(features).squeeze()\n",
    "\n",
    "class PredictiveTaskHead(nn.Module):\n",
    "\t\n",
    "\tdef __init__(self, n_classes=2, p=0.2):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.clf = nn.Sequential(\n",
    "\t\t\tnn.Linear(1768, 1024),\n",
    "\t\t\tnn.Dropout(p=0.2),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(p=0.2),\n",
    "\t\t\tnn.Linear(1024, 1024),\n",
    "\t\t\tnn.Dropout(p=0.2),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(1024, n_classes)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, features):\n",
    "\t\t# features: (b,1768)\n",
    "\t\treturn self.clf(features)\n",
    "\n",
    "class CounterfactualTaskHead(nn.Module):\n",
    "\t\n",
    "\tdef __init__(self, p=0.2):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.clf = nn.Sequential(\n",
    "\t\t\tnn.Linear(1768, 1024),\n",
    "\t\t\tnn.Dropout(p=0.2),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(p=0.2),\n",
    "\t\t\tnn.Linear(1024, 1024),\n",
    "\t\t\tnn.Dropout(p=0.2),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(1024, 1),\n",
    "            nn.Sigmoid()\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, features):\n",
    "\t\t# features: (b,1768)\n",
    "\t\treturn self.clf(features).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "043119c4-9382-4d98-b470-10f3cd18d64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ['0', '1', '2', '3', '4', '5', 'yes', 'no', 'rubber', 'metal', 'sphere', 'cube', 'cylinder', 'gray', 'brown', 'green', 'red', 'blue', 'purple', 'yellow', 'cyan']\n",
    "option_id_map = {\n",
    "    o:i for i,o in enumerate(options)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ebf615-52f2-4356-a522-927ff6de9bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7526130e-99ee-435c-bd71-5027ee47951e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertCNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d62d1636-c058-4cc8-aca8-61babdf7bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "274dc0d8-a8d1-4f9a-a021-0d816258151a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b63d752fbf74ab5b007e72824a94099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d065e76ad84a04b6af780390706690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c560a68852c41a6bacbe69c13e02d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2cf17c8f-848d-4216-947d-b2ccb2035fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pos_emb.pe = model.pos_emb.pe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2a91113b-2b0d-444f-bbd4-4ee4b2fabc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 320, 480])\n",
      "torch.Size([900, 320, 480])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8280, -0.1636, -0.5451,  ...,  0.9999, -0.9072,  0.9909],\n",
       "        [-0.9929, -0.5160, -0.4730,  ...,  0.9999, -0.9261,  0.9942]],\n",
       "       device='cuda:0', grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks = tokenizer(['How many collisions happen in this frame?', 'What would happen if the blue ball disappeared?'], return_tensors='pt').to(device)\n",
    "img = torch.randn((2,3,320,480)).to(device)\n",
    "model(img, toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1a3f3b-a50b-4167-96b9-95b4ace08937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
